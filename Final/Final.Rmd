---
title: 'Non- and private-voting trends: Kaiser survey data 12-2020'
author: "Steve Linberg"
date: "23 January 2021"
output:
  pdf_document: default
  html_notebook: default
subtitle: DACSS 601 Final Paper
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
```{r tidyverse, include=FALSE}
library(tidyverse)
```
```{r apa library, include=FALSE}
# Use the APA library for citing chicq.test results
library(apa)
```

## Introduction

In both the 2016 and 2020 U.S. presidential elections, there was a great deal of discussion in the media and among political pundits about the challenges of predicting the outcomes. Nearly every major news source and polling organization reported a significant polling advantage for Democratic candidate Hillary Clinton in the 2016 election, right up to election day, with most forecasts at or above a [90% likelihood](https://www.reuters.com/article/us-usa-election-poll/clinton-has-90-percent-chance-of-winning-reuters-ipsos-states-of-the-nation-idUSKBN1322J1) of a Clinton victory. Most major polls [(with some early exceptions)](https://fortune.com/2016/05/25/election-polls-hillary-clinton-donald-trump/) showed her with a comfortable lead throughout the primary season.  Republican Donald Trump's victory in 2016 was a startling surprise for many observers (and voters).

Similarly, in 2020, most major polls and forecsts expected, and predicted, strong Democratic gains in the House and Senate, along with capturing the White House (in what was commonly referred to as the incoming "blue wave"). While Democrats did win the presidency, it was by a narrower margin than some predicted; gains in the Senate were smaller than thought to be likely (Democrats gained 4 seats, but 5 races thought to be competitive remained in Republican hands[^dem_races]), and Democrats actually lost 11 seats in the House. Once again, the strength of Republican turnout was stronger than many pundits (and statisticians) expected.

One popular theory that has sought to explain this discrepancy between predicted and actual outcomes is the idea of the "hidden voter," where polls fail to take into account a significant portion of the voting population because they either (a) do not participate in polls, or (b) do not respond truthfully when asked which candidate(s) they support. One possible reason for this could involve an aversion to unwanted social pressure from openly supporting controversial candidates. Put simply, the theory was that a lot of voters secretly supported, and voted for, Donald Trump, but did not openly support him or answer truthfully in polls.

There has been a great deal of speculation about what might explain thus undercounting or underestimating of support for conservative candidates in the national elections since 2016. Theories abound, from methodological critiques of polling methodologies to rather more fantastical suspicions of deliberate sabotage by poll respondents in an effort to discredit polling and the media in general. In this paper, we will look at a more benign theory: that conservative voters are less likely to disclose their political ideology or voting choices, creating an underestimation of their electoral power that is not accounted for by polling.

We will use a December 2020 study by the Kaiser Family Foundation which looks at opinions on a range of questions relating to COVID-19, the 2020 election, and aspects of political ideology. Although the scope of the survey is broad, we will focus on respondents who either declined to divulge who they had voted for, what their ideology is, or both, and see if we can find data to support the notion that these voters are likely to be more conservative than liberal.

## Data

```{r load raw_data, include=FALSE}
# Note: the data file `31118130.csv` is a symlink to the original file in the "../3 + 4" directory in this repository. 
raw_data <- read_csv("31118130.csv")
# num_rows is used in calculations
num_rows <- nrow(raw_data)
# num_cols is only displayed
num_cols <- ncol(raw_data)
```

The data source for this paper is the Kaiser Family Foundation poll *December 2020 Kaiser Health Tracking Poll/COVID-19 Vaccine Monitor*[^study], which may be seen at:

https://ropercenter.cornell.edu/ipoll/study/31118130

It consists of `r nrow(raw_data)` observations of `r ncol(raw_data)` variables, resulting from a total of approximately 40 questions and conducted by telephone. It includes an oversample of prepaid ("pay as you go") telephone numbers (25% of the total number of cell phone numbers dialed). The majority of the questions are concerned with the Affordable Care Act, COVID-19, the 2020 U.S. presidential election, and political ideology.

Two key variables, `ideology` and `voted2`, provide an immediate sense of the overall political leanings of respondents. 
`ideology` is a response to the question:

> Would you say your views in most political matters are liberal, moderate, or conservative?

The options given for response were:

- Liberal
- Moderate
- Conservative
- **(DO NOT READ)** Don't know
- **(DO NOT READ)** Refused

Given these options, the breakdown of respondents' answers is:

```{r self_reported_ideology_plot, echo=FALSE}
raw_data %>% 
#  ggplot(aes(x=ideology) ) +
  ggplot(aes(x=reorder(ideology,ideology,function(x)-length(x))
# Color doesn't add to this plot, the colors don't mean anything
# and there's no reason to hard-code categories
#             ,fill=ideology
  )) +
  geom_bar(show.legend = FALSE) +
  labs(title = "ROPER-31118130 poll respondents self-reported ideology",
       x = "")
```
```{r ideology_count_calculations, echo=FALSE}
# store the frequency table for ideology
ideology_count <- table(raw_data$ideology)

# Only reference constants once
ideology_ct_m <- ideology_count['Moderate']
ideology_ct_c <- ideology_count['Conservative']
ideology_ct_l <- ideology_count['Liberal']
ideology_ct_mcl <- ideology_ct_m + ideology_ct_c + ideology_ct_l
ideology_pct_m = round(100 * ideology_ct_m / ideology_ct_mcl,1)
ideology_pct_c = round(100 * ideology_ct_c / ideology_ct_mcl,1)
ideology_pct_l = round(100 * ideology_ct_l / ideology_ct_mcl,1)
```

A small number of respondents either didn't know or refused to disclose their political ideology, but among the `r ideology_ct_mcl` that did, 
`r ideology_ct_m` (`r ideology_pct_m`%) 
identified as Moderate, 
`r ideology_ct_c` (`r ideology_pct_c`%) 
identified as Conservative, and 
`r ideology_ct_l` (`r ideology_pct_l`%) 
identified as Liberal.

As this is a self-reported description, we must be careful in drawing too deeply from this variable in isolation, as the labels Moderate, Conservative and Liberal are not defined by the survey questions, but they do suggest a reasonable balance of political ideologies if we consider them as roughly "Center," "Right" and "Left" (respectively).

(A note on terminology: in this paper, the terms Moderate, Conservative and Liberal are capitalized when referring to survey categories, rather than the general meanings or usage of the words; the survey does not actually define the terms, nor was it defined for the respondents.)

A look at the `voted2` variable yields some interesting observations. The text of the question is

> In the election for U.S. president, did you vote for (Donald Trump) or (Joe Biden), or someone else?

The response options were:

- Donald Trump
- Joe Biden
- Someone else (Specify)
- **(DO NOT READ)** Donâ€™t know
- **(DO NOT READ)** Refused

```{r voted2_plot, echo=FALSE}
raw_data %>% 
  ggplot(aes(x=reorder(voted2,voted2,function(x)-length(x))
# Color doesn't add to this plot, the colors don't mean anything
# and there's no reason to hard-code categories
  )) +
  geom_bar(show.legend = FALSE) +
  labs(title = "ROPER-31118130 poll respondents 2020 presidential vote",
       x = "")
```
There are three noteworthy observations here:

```{r voted2_count_calculations, echo=FALSE}
# Store the frequency table for votes
voted2_count <- table(raw_data$voted2)

# Again, only reference constants once
voted2_ct_biden <- voted2_count['Joe Biden']
voted2_ct_trump <- voted2_count['Donald Trump']
voted2_ct_refused <- voted2_count['Refused']
voted2_ct_else <- voted2_count['Someone else']
voted2_ct_dontknow <- voted2_count["Don't know"]
voted2_ct_btred <- voted2_ct_biden + voted2_ct_trump + voted2_ct_refused + 
  voted2_ct_else + voted2_ct_dontknow
voted2_ct_trump_refused <- voted2_ct_trump + voted2_ct_refused

voted_pct_biden <- round(100 * voted2_ct_biden / voted2_ct_btred,1)
voted_pct_trump <- round(100 * voted2_ct_trump / voted2_ct_btred,1)
voted_pct_refused <- round(100 * voted2_ct_refused / voted2_ct_btred,1)
voted_pct_trump_refused <- round(100 * voted2_ct_trump_refused / voted2_ct_btred,1)
voted_pct_total <- round(100 * voted2_ct_btred / num_rows,1)

voted2_nonvotes <- num_rows - voted2_ct_btred
voted_pct_nonvotes <- round(100 * voted2_nonvotes / num_rows,1)
```
1. **A strong preference towards Joe Biden**<br>
Despite a somewhat balanced `ideology` variable, of the `r voted2_ct_btred` respondents who voted in the election,
`r voted2_ct_biden` (`r voted_pct_biden`%) voted for Joe Biden,
`r voted2_ct_trump` (`r voted_pct_trump`%) voted for Donald Trump, and
`r voted2_ct_refused` (`r voted_pct_refused`%) refused to answer the question (see below). Joe Biden won the national popular vote with [51.3% to Donald Trump's 46.9%](https://cookpolitical.com/2020-national-popular-vote-tracker), which means the results from this survey disproportionately represent Joe Biden voters as compared the national totals.

1. **A significant number of non-votes**<br>
`r voted2_nonvotes` respondents (`r voted_pct_nonvotes`%) of the total did not vote ("NA") in the presidential election, and (`r voted_pct_total`%) did. While the visual impression of nonvotes in the diagram above seems high, the respondents to this poll still significantly exceeded the national turnout rate of 66.7%.[^national_turnout]

1. **A significant number of "Refused" (to answer) responses**<br>
As noted above, `r voted2_ct_refused` respondents (`r voted_pct_refused`% of the total who voted) refused to answer who they voted for. Even if it turned out that 100% of these respondents had voted for Trump, it would still only result in a total turnout of `r voted_pct_trump_refused`%, well short of his 46.9% national total. The Trump vote is still under-represented in this poll.

This final observation, however, does not imply that the distribution of ideology within the group of voters who refused to answer who they voted for does not fit the national average, and this is the group we are going to investigate further, with the goal of trying to get a sense of how these respondents might have voted based on answers to other questions from the survey.

### Observation 1: The ideology of "Refused" voters

The most obvious observation to make would be: how do the voters who refused to answer who they voted for for president in the 2020 election (hereafter "private voters") self-report their political views?

```{r ideology_by_refused_voted2_construction, echo=FALSE}
ideology_by_refused_voted2 <- raw_data %>%
  select(ideology, voted2) %>%
  filter(voted2 == "Refused")
voted2_refused_count <- table(ideology_by_refused_voted2$ideology)
# voted2_refused_count
```

```{r ideology_by_refused_voted2 plot, echo=FALSE}
ideology_by_refused_voted2 %>% 
  ggplot(aes(x=reorder(ideology,ideology,function(x)-length(x))
  )) +
  geom_bar(show.legend = FALSE) +
  labs(title = "\"Private voters\" by ideology",
       x = "")
```
We can see from this that a majority of respondents who did not disclose which presidential candidate they voted for self-identified as either Conservative or Moderate. 

To take a deeper look at this tendency, we can convert the ideological share of each group of voters - all voters, and "private voters" - into percentages of their respective sums, and compare the percentages. The following chart shows the difference in these percentages; we can see that a higher percentage of "private voters" self-report as Conservative than all voters do, a smaller percentage of them self-report as Moderate than all voters, and a significantly smaller percentage self-report as Liberal. 

```{r ideology_props plot, echo=FALSE, warning=FALSE}
# Combine proportion tables for ideology for all voters, and for those who
# refused to say who they voted for.
ideology_props <- as.data.frame(prop.table(ideology_count)) %>%
  # Remane the "Freq" column to "all"
  rename(all = Freq)
# Import the voted2_refused_count column into a new "refused" column
ideology_props$refused <- prop.table(voted2_refused_count)

# Flatten the "all" and "refused" columns into "scope" and "value"
ideology_props <- ideology_props %>%
  gather('all', 'refused', key = 'scope', value = 'pct')
# Convert the 0-1 pct value to 0-100 for display purposes
# Round to 2 digits for display over bar
ideology_props$pct <- round(ideology_props$pct * 100,1)

ideology_props %>% 
  ggplot(mapping = aes(x=Var1, y=pct, fill=scope)) + 
  labs(title = "Poltical ideology by `voted2` response scope", 
       subtitle = "A comparison of ideology for all voting respondents vs. refused voters (by percentages)",
       x = "Ideology",
       y = "Percent"
       ) +
  scale_fill_discrete(name="Scope", labels = c("All voters", "Private voters")) +
  geom_bar(stat = "identity", position = "dodge") +
  # Add the percentages on top of each bar
  geom_text(aes(label=pct), position=position_dodge(width=0.9), vjust=-0.25)
```
```{r ideology_chisq and ideology_fisher, echo=FALSE, warning=FALSE}
# Create a matrix of the above data so we can run a chisq.test.
# This is almost certainly far more complicated than necessary and has cost me at least a day,
# but it's time to wrap this up, so do it the hard way and come back to it later.

# Begin with the frequency table of ideology for all respondents.
#Conservative   Don't Know      Liberal     Moderate      Refused 
#         527           68          424          617           40
ideology_matrix <- as.matrix(ideology_count)

# Add the frequency table for refused voters to the matrix via cbind.
#Conservative   Don't Know      Liberal     Moderate      Refused 
#          38            6           16           37           14
ideology_matrix <- cbind(ideology_matrix, voted2_refused_count)
# Resulting matrix:
#                 voted2_refused_count
#Conservative 527                   38
#Don't Know    68                    6
#Liberal      424                   16
#Moderate     617                   37
#Refused       40                   14

# Finally, run the chisq test.
ideology_chisq <- chisq.test(ideology_matrix)
ideology_fisher <- fisher.test(ideology_matrix)
```

These differences are statistically significant (`chisq.test`: (`r chisq_apa(ideology_chisq, format="text", print=FALSE)`); `fisher.test`: (`r ideology_fisher$alternative`), $p=$ `r ideology_fisher$p.value`), and appear to show that voters who refused to disclose who they voted for were more likely to self-report as Conservative, (34% to 31%) and significantly less likely to report as Liberal (14% to 25%). This supports our initial hypothesis that voters who refuse to disclose their ideology are likelier to identify as Conservative.

### Observation 2: Hidden data in "Refused" ideology category

However, there is still one problem with this conclusion: As we can see in the chart, 12.6% of "private voters" also declined to share their ideology, a far higher percentage than that of the total of all voters. With perfect knowledge, we could reduce the "Refused" column down to a level similar to the total percentage of 2.4%, and redistribute most of among the other categories. Although such a scenario would seem to be very unlikely, what if it were true that most of the voters who refused to disclose their ideology were in fact Liberal? If we were to move the bulk of the "Refused" voters into the Liberal column, we get a chart with fewer overall differences.

The following chart represents ***this hypothetical scenario, and not the actual data from the study***; it is for visualization and analysis only. We will make an assumption that 11 of the 14 "private voters" who refused to disclose their ideology are in fact Liberal, and adjust the data accordingly. This would represent approximately 80% of the total of the "private voters".

```{r fake_ideology_props plot, echo=FALSE, warning=FALSE}
# Make a copy of the ideology_props data.frame
fake_ideology_props <- ideology_props
# > ideology_props
#           Var1   scope  pct
# 1  Conservative     all 31.4
# 2    Don't Know     all  4.1
# 3       Liberal     all 25.3
# 4      Moderate     all 36.8
# 5       Refused     all  2.4
# 6  Conservative refused 34.2
# 7    Don't Know refused  5.4
# 8       Liberal refused 14.4
# 9      Moderate refused 33.3
# 10      Refused refused 12.6

# Move 9.9 points from "Refused" to "Liberal".
# (this represents moving 11 of 14 voters, roughly 80%)
fake_ideology_props[10,3] <- fake_ideology_props[10,3] - 9.9
fake_ideology_props[8,3] <- fake_ideology_props[8,3] + 9.9
# > fake_ideology_props
#            Var1   scope  pct
# 1  Conservative     all 31.4
# 2    Don't Know     all  4.1
# 3       Liberal     all 25.3
# 4      Moderate     all 36.8
# 5       Refused     all  2.4
# 6  Conservative refused 34.2
# 7    Don't Know refused  5.4
# 8       Liberal refused 24.3
# 9      Moderate refused 33.3
# 10      Refused refused  2.7

fake_ideology_props %>% 
  ggplot(mapping = aes(x=Var1, y=pct, fill=scope)) + 
  labs(title = "HYPOTHETICAL redistribution of `voted2` response scope", 
       subtitle = "A hypothetical redistribution of approx. 80% of \"Refused\" private voters into \"Liberal\"",
       x = "Ideology",
       y = "Percent"
       ) +
  scale_fill_discrete(name="Scope", labels = c("All voters", "Private voters")) +
  geom_bar(stat = "identity", position = "dodge") +
  # Add the percentages on top of each bar
  geom_text(aes(label=pct), position=position_dodge(width=0.9), vjust=-0.25)
```

```{r fake_ideology_chisq and ideology_fisher, echo=FALSE, warning=FALSE}
# Make a copy of the ideology matrix
fake_ideology_matrix <- ideology_matrix
#                  voted2_refused_count
# Conservative 527                   38
# Don't Know    68                    6
# Liberal      424                   16
# Moderate     617                   37
# Refused       40                   14

# Staying with the approximately 80% threshold, move 11 of the 14 "Refused" voters into "Liberal".
fake_ideology_matrix[5,2] <- fake_ideology_matrix[5,2] - 11
fake_ideology_matrix[3,2] <- fake_ideology_matrix[3,2] + 11
#                  voted2_refused_count
# Conservative 527                   38
# Don't Know    68                    6
# Liberal      424                   27
# Moderate     617                   37
# Refused       40                    3

# Now, run the chisq test on this hypothetical data.
fake_ideology_chisq <- chisq.test(fake_ideology_matrix)
fake_ideology_fisher <- fisher.test(fake_ideology_matrix)
```

With this hypothetical redistribution of 9.9 percentage points from "Refused" into Liberal, we get results that are much closer in balance to the ideologies of all voters. These differences would no longer be statistically significant (`chisq.test`: (`r chisq_apa(fake_ideology_chisq, format="text", print=FALSE)`), and this hypothetical data would suggest that there is *no difference* in ideology between voters who did, and did not, reveal who they voted for in the election.

It is very important to note that this far, ***there is no evidence whatsoever*** that there is a significant hidden population of Liberal votes lurking within the actual 12.6% of voters who refused to disclose who they voted for; however, until we rule that out, we need to be cautious in drawing conclusions about the ideologies of "Private" voters in this study.

This merits further investigation. How can we show that this hypothetical scenario - that the bulk of the voters who refused to disclose either their political ideology or who they voted for are actually Liberal? One way would be to compare their answers to other questions on the survey which correlate strongly with, or against, responses from Liberal voters.

One limiting factor here is that we are now down to a very small subset of our initial data; we are looking at 14 out of `r num_rows` voters, `r round(100 * 14/num_rows, 2)`% of the total. This is a small enough sample that statistical tests and graphs will be of dubious value; its small size, however, does make strong trends within it less unlikely, contributing to the overall difficulty of drawing conclusions from it.

### Observation 3: Some manual examinations do lean Liberal

In this final observation, we extract the rows of responses for the 14 voters who disclosed neither who they voted for, nor their ideology, and compare their responses to that of the overall data set.

```{r get_private_refused_voters, echo=FALSE}
# Get the rows for private voters who refused to disclose their ideology
private_refused_voters <- raw_data %>%
  filter(voted2 == "Refused" & ideology == 'Refused')

```

#### Question 1: The ACA

Question 1 refers to the Affordable Care Act. The text of the question reads:

> What would you like to see the next presidential administration and Congress do when it comes to the health care law?

The offered responses are:

- Build on what the law does
- Keep the law as it is
- Scale back what the law does
- Repeal the entire law
- **(DO NOT READ)** None of these/Something else (Vol.)
- **(DO NOT READ)** Donâ€™t know
- **(DO NOT READ)** Refused

Looking at the results for the entire survey, we can see a tendency for strong support for "Build on what the law" does from Liberal respondents., while "Repeal the entire law" is stronger among Conservative respondents (all values in percentages by ideology):

```{r q1-raw, echo=FALSE}
table(raw_data$q1,raw_data$ideology) %>%
  # margin=2: sum columns for percentages
  prop.table(margin=2) %>% 
  # turn to percentages rounded to 2 digits
  `*`(100) %>% round(2)
```

This shows strong Liberal support for the response "Build on what the law does" (72%), while "Keep the law as it is" lacks strong support among both Liberals and Conservatives (and more among "Don't Know", but this group only represents approximately 4% of the respondents total). 

If we look at the answers to this question among our small, 14-voter sample, we see:

```{r q1-sample, echo=FALSE}
prop.table(table(private_refused_voters$q1)) %>% `*`(100) %>% round(2)
```
This shows close-to-even support for "Build on what the law does", "Keep the law as it is," and "Repeal the entire law". The overall results could be interpreting as tilting slightly towards an overall sentiment consistent with a Liberal distribution. Although the sample size is small, this is our first indication that it is indeed possible that our (small) hidden population of ideology tilts Liberal.

#### Question 5: Reporting on the seriousness of Coronavirus

Question 5 on the survey reads:

> Thinking about what is said in the news, in your view is the seriousness of coronavirus (generally exaggerated), generally correct, or is it (generally underestimated)?

The offered responses are:

- Generally exaggerated
- Generally correct
- Generally underestimated
- **(DO NOT READ)** Don't know
- **(DO NOT READ)** Refused

The responses of the entire survey are:

```{r q5-raw, echo=FALSE}
table(raw_data$q5,raw_data$ideology) %>%
  # margin=2: sum columns for percentages
  prop.table(margin=2) %>% 
  # turn to percentages rounded to 2 digits
  `*`(100) %>% round(2)
```

We can see here that nearly 50% of Liberals respond with "Generally correct", an assessment shared by only 22% of Conservatives. Our small sample shows a 42% majority of responses of "Generally correct" among the respondents who did not disclose ideology or presidential choice:

```{r q5-sample, echo=FALSE}
prop.table(table(private_refused_voters$q5)) %>% `*`(100) %>% round(2)
```
This sample, although small, continues to support the notion of a Liberal-direction ideological lean for these respondents.

#### Question 9: On mask-wearing

Question 9 on the survey reads:

> Which comes closer to your view: wearing a mask to prevent the spread of COVID-19 (is a personal choice) OR wearing a mask (is part of everyoneâ€™s responsibility to protect the health of others)?

The offered responses are:

- Wearing a mask is a personal choice
- Wearing a mask is part of everyoneâ€™s responsibility to protect the health of others
- **(DO NOT READ)** Both (Vol.)
- **(DO NOT READ)** Neither (Vol.)
- **(DO NOT READ)** Don't know
- **(DO NOT READ)** Refused

The responses of the entire survey are:

```{r q9-raw, echo=FALSE}
table(raw_data$q9,raw_data$ideology) %>%
  # margin=2: sum columns for percentages
  prop.table(margin=2) %>% 
  # turn to percentages rounded to 2 digits
  `*`(100) %>% round(2)
```

This shows that Liberals overwhelmingly (92%) choose the response "Wearing a mask is part of everyone's responsibility to protect the health of others", whereas Conservatives are close to split between this response and "Wearing a mask is a personal choice". Our small survey shows:

```{r q9-sample, echo=FALSE}
prop.table(table(private_refused_voters$q9)) %>% `*`(100) %>% round(2)
```

So once again, we see a strong - though not overwhelming - Liberal tilt in the responses.

The answers to these questions indicate that there could indeed be a Liberal ideological bias - possibly even a strong one - among the respondents who chose not to reveal either their ideology or their presidential choice.

We saw above that if 80% of the respondents in this category were of (a hidden/unreported) Liberal ideology, it would be enough to balance out the overall ideological responses among voters who refused to disclose who they voted for, and *that* would be sufficient to prevent us from drawing the conclusion that it tends to be conservative voters who are more likely to conceal who they vote for.

```{r fake_ideology_chisq_2 and ideology_fisher, echo=FALSE, warning=FALSE}
# Make another copy of the ideology matrix
fake_ideology_matrix_2 <- ideology_matrix
#                  voted2_refused_count
# Conservative 527                   38
# Don't Know    68                    6
# Liberal      424                   16
# Moderate     617                   37
# Refused       40                   14

# Take the 11 refused, and put 6 into liberal, 3 into conservative and 2 into moderate.
fake_ideology_matrix_2[5,2] <- fake_ideology_matrix_2[5,2] - 11
fake_ideology_matrix_2[3,2] <- fake_ideology_matrix_2[3,2] + 5
fake_ideology_matrix_2[1,2] <- fake_ideology_matrix_2[1,2] + 3
fake_ideology_matrix_2[4,2] <- fake_ideology_matrix_2[4,2] + 3
#                  voted2_refused_count
# Conservative 527                   38
# Don't Know    68                    6
# Liberal      424                   27
# Moderate     617                   37
# Refused       40                    3

# Now, run the chisq test on this hypothetical data.
fake_ideology_chisq_2 <- chisq.test(fake_ideology_matrix_2)
```

In fact, with only 5 of the 11 "Refused" voters being redistributed were added to the Liberal total, and the remaining 6 distributed in approximately equal proportions among the remaining choices (3 each to Conservative and Moderate), our `chisq.test` results ate still `r chisq_apa(fake_ideology_chisq_2, format="text", print=FALSE)`[^data_note_1]. So a Liberal tilt in these voters is not even needed to prevent us from supporting our initial hypothesis, and the answers we saw to the questions above provide fairly strong support for the existence of this bias. All that is necessary is a redistribution - or reveal - of the "Refused" voters' hypothetical ideologies. It is the concealing of the ideologies, rather than their tilt, which creates the low p-value in the first `chisq.test` examining the differences in ideology between all of the respondents, and those who declined to disclose them.

## Conclusion

This paper looked at the question of whether voters who chose not to reveal which presidential candidate they voted for, in data from a recent Kaiser Family Foundation survey, had a hidden ideological bias that could account for some of the difficulty in predicting the strength of Conservative turnout in recent elections.

Based on the ambiguity of the ideology of respondents who refused to answer who they voted for, and on the analysis of responses to other questions this subset of respondents answered, we cannot support the hypothesis, which a first-level look at the data seemed to suggest, that voters who choose not to reveal who they vote for have any particular ideological bias compared to those who do.

It also does not *disprove* this possibility, of course. But these results could be surprising to those (including this author) who accepted the general concept of some degree of Conservative bias in undisclosed ideological preferences among voters. It is possible that such a bias exists, but this examination of this dataset does not support it.

## Reflection

The process of writing this paper was rather grueling, chiefly because I went through the class essentially solo and online (during the January term), without peer support or other students to work with, so there were several "rabbit holes" I ended up going down (for several days apiece) that probably could have been avoided with a peer group. Professor Rolfe generously met with me once a week for questions and discussion, which was helpful, but I still think I would have gotten through with less wasted time if I'd been able to work actively with other students.

Some of the time-sinks would be expected in any circumstance of bootstrapping onself into a new area of knowledge; I have a long background in computer programming in various languages dating back to the early 1980s, but they are/were mostly low-level languages initially (C and assembly), and in more recent years, Perl, Objective-C, PHP and Swift, so I have become increasingly used to strongly-typed languages (or the ability to activate strong typing in more permissive languages), and R is pretty different in some important ways. Although the basics of the language are straightforward, some of the nuances about underlying data structures are quite complex (like the differences between sometimes-interchangeable vectors, data frames, tables and matrices, and their modes of access), and without strict typing, it's possible to make errors that are difficult to detect.

In particular, I got hung up pretty hard on the proper way to run `chisq.test` on frequency tables from the data, and initially was getting an erroneous result due to bad inputs rather than bad data. My case was specific enough that doing productive online searches was arduous and probably more confusing than helpful; I ended up rolling back to a completely manual data set and doing a lot of experimenting to first get the correct results, and then did a lot of work to reverse-engineer the manual data back to the proper references for the actual data set. Someone more experienced than me in R could probably have identified my issue immediately, but it took a long time to find on my own.

Once I had that sorted out and began to increase my ability to query the data and look for trends, the process became more enjoyable, and I was surprised to come upon the conclusion that I did - or rather, to find a *lack* of statistical evidence to support my own bias. This is actually quite exciting to me intellectually, even if it feels like something of an ego-check on something I assumed was true about myself. This is exactly why we need statistics and analytics in social science. I would not have had the mechanisms for looking at questions of my own bias prior to undertaking this paper (and was not expecting to find any in its execution).

I can see at this point how powerful deep fluency with data query languages like R, and with statistical principles, will be in future research. I have a lot to learn about R still, and about statistical methods, but I need no convincing of their utility. I look forward to continuing to develop both in future classes as I move through the DACCS program.

[^study]: Henry J. Kaiser Family Foundation. Kaiser Family Foundation Poll: December 2020 Kaiser Health Tracking Poll/COVID-19 Vaccine Monitor, 2020 [Dataset]. Roper #31118130, Version 2. SSRS [producer]. Cornell University, Ithaca, NY: Roper Center for Public Opinion Research [distributor]. doi:10.25940/ROPER-31118130
[^dem_races]: Iowa, Main, Montana, North and South Carolina: see https://www.nytimes.com/interactive/2020/11/03/us/elections/results-senate.html
[^national_turnout]: see https://www.statista.com/statistics/1184621/presidential-election-voter-turnout-rate-state/
[^data_note_1]: for our purposes here, we retain 3 of the 14 voters in a "Refused" category, rather than redistributing them all among the other choices, in order to retain a percentage-wise balance with the full data set and avoiding creating a 0-value inflection point for the `chisq.test` to factor in, which would skew the results more strongly than our approximation of 3. 

```{r manual_chisq_UNUSED, include=FALSE}
# This block of code was an emergency measure to create a manual frequency table.
# A calculated method, though still overly complex, is in the next code block.
group <- c("all", "all", "all", "all", "all", "refused", "refused", "refused", "refused", "refused")
ideology <- c("Moderate", "Conservative", "Liberal",  "Don't Know", "Refused", "Moderate", "Conservative", "Liberal",  "Don't Know", "Refused")
totals <- c(617,527,424,68,40,37,38,16,6,14)
A <- data.frame(group,ideology,totals)
A_xtabs <- xtabs(totals~group+ideology,data=A)
# This gives the same results as the ideology_chisq block below.
chisq.test(A_xtabs,correct=F)
#fisher.test(A_xtabs)

obs <- c(37,38,16,6,14)
exp <- c(617/1676,527/1676,424/1676,68/1676,40/1676)
chisq.test(obs, p=exp)
```